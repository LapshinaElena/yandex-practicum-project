{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76d3da",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab5530",
   "metadata": {},
   "source": [
    "### Содержание:\n",
    "\n",
    "* [Загрузка данных](#chapter1)\n",
    "    * [Вывод](#section_1_1)\n",
    "* [Использование предобученной модели для английского языка DistilBERT](#chapter2)\n",
    "    * [Логистическая регрессия](#section_2_1)\n",
    "    * [LightGBM](#section_2_2)\n",
    "    * [Случайный лес](#section_2_3)\n",
    "    * [Вывод](#section_2_4)\n",
    "* [Применение метода TF-IDF](#chapter3)\n",
    "    * [Логистическая регрессия](#section_3_1)\n",
    "    * [LightGBM](#section_3_2)\n",
    "    * [Случайный лес](#section_3_3)\n",
    "    * [Вывод](#section_3_4)\n",
    "* [Тестирование лучшей модели](#chapter4) \n",
    "* [Итоговый вывод](#chapter5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c165c",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a3c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (4.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0704bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: torch==1.12.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lapsh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd305025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lapsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lapsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import notebook\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ac570",
   "metadata": {},
   "source": [
    "### Загрузка данных <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b26343",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\lapsh\\yandex-praktikum-projects\\toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcc6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54158b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e400cf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2be82",
   "metadata": {},
   "source": [
    "#### Вывод <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "Всего в базе данных 159571 записей. Текст комментариев - английский. Отрицательные комментарии составляют 10.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707c24d",
   "metadata": {},
   "source": [
    "### Использование предобученной модели для английского языка DistilBERT <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018ad0d",
   "metadata": {},
   "source": [
    "Для решения поставленной задачи попробуем применить предобученную модель для английского языка. Использовать будем DistilBERT. На ней мы выполним токенизацию текстов и создадим эмбеддингию. Полученные эмбеддинги будем использовать в других моделях для непосредственно классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad59f6",
   "metadata": {},
   "source": [
    "Из-за органиченных ресурсов, мы не сможем использовать весь набор данных. Ограничимся 10 тыс. записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a97fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data.sample((10000), random_state=12345).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf194cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8960\n",
       "1    1040\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2395fc",
   "metadata": {},
   "source": [
    "Структура отобранных данных сопоставима с исходными. Отрицательные комментарии составляют 10.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad068b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692d7f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f56acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токинезация\n",
    "tokenized = data_1['text'].apply((lambda x: tokenizer.encode(x, max_length=512, truncation=True, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d1fbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним 0 векторы, длина которых меньше максимальной\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5e461f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117863cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# маска важных токенов\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1b864",
   "metadata": {},
   "source": [
    "Начнём преобразование текстов в эмбеддинги. Используем библиотеку tqdm для отображения индикатора прогресса. В Jupyter применим функцию notebook() из этой библиотеки. \n",
    "Эмбеддинги модель BERT создаёт батчами. Чтобы хватило оперативной памяти, сделаем размер батча небольшим: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f242550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae6b4a08831487a93b10e34d0696c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100 \n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf7c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# соберём все эмбеддинги в матрицу признаков вызовом функции concatenate():\n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fec1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_1['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f9f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.15, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15992a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae4778a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a39cd06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e30d599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd63ed",
   "metadata": {},
   "source": [
    "Рассмотрим 3 модели: логистическая регрессия, LightGBM, случайный лес."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95396e4",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3efec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "237b80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log = {\n",
    "    'solver': ['liblinear', 'sag','saga','newton-cg'],\n",
    "    'C': [0.5,1.0,1.5],\n",
    "    'intercept_scaling':[0.5,1.0,1.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d58c97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                random_state=12345),\n",
       "                   param_distributions={'C': [0.5, 1.0, 1.5],\n",
       "                                        'intercept_scaling': [0.5, 1.0, 1.5],\n",
       "                                        'solver': ['liblinear', 'sag', 'saga',\n",
       "                                                   'newton-cg']},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_grid = RandomizedSearchCV(model_log, params_log, scoring='f1')\n",
    "model_log_grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbf052d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия. Гиперпараметры  {'solver': 'liblinear', 'intercept_scaling': 1.0, 'C': 1.0}\n",
      "Логистическая регрессия. F1  0.6649972047874526\n"
     ]
    }
   ],
   "source": [
    "print('Логистическая регрессия. Гиперпараметры ', model_log_grid.best_params_)\n",
    "print('Логистическая регрессия. F1 ', model_log_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c294a5",
   "metadata": {},
   "source": [
    "#### LightGBM <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4104b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = LGBMClassifier(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f22fe0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': ['regression','binary'],\n",
    "    'boosting_type' : ['dart','gbdt','goss'],\n",
    "    'max_depth': [15,30],\n",
    "    'num_leaves': [10,200,250]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7c31a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                            random_state=12345),\n",
       "                   param_distributions={'boosting_type': ['dart', 'gbdt',\n",
       "                                                          'goss'],\n",
       "                                        'max_depth': [15, 30],\n",
       "                                        'num_leaves': [10, 200, 250],\n",
       "                                        'objective': ['regression', 'binary']},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb_grid = RandomizedSearchCV(model_lgb, lgb_params, scoring='f1')\n",
    "model_lgb_grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98e4bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM. Гиперпараметры  {'objective': 'binary', 'num_leaves': 250, 'max_depth': 15, 'boosting_type': 'goss'}\n",
      "LightGBM. F1  0.6693750278114453\n"
     ]
    }
   ],
   "source": [
    "print('LightGBM. Гиперпараметры ', model_lgb_grid.best_params_)\n",
    "print('LightGBM. F1 ', model_lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc23356",
   "metadata": {},
   "source": [
    "#### Случайный лес <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8db41270",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd9c4fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\n",
    "    'max_depth': range(1, 26),\n",
    "    'n_estimators':range(1, 11)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d25872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                    random_state=12345),\n",
       "                   param_distributions={'max_depth': range(1, 26),\n",
       "                                        'n_estimators': range(1, 11)},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest_grid = RandomizedSearchCV(model_forest, forest_params, scoring='f1')\n",
    "model_forest_grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e524d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес. Гиперпараметры  {'n_estimators': 9, 'max_depth': 9}\n",
      "Случайный лес. F1  0.608670216909341\n"
     ]
    }
   ],
   "source": [
    "print('Случайный лес. Гиперпараметры ', model_forest_grid.best_params_)\n",
    "print('Случайный лес. F1 ', model_forest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0979234",
   "metadata": {},
   "source": [
    "#### Вывод <a class=\"anchor\" id=\"section_2_4\"></a>\n",
    "Ни одна из расмотренных моделей не достигла требуемого значения метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e992b67",
   "metadata": {},
   "source": [
    "### Применение метода  TF-IDF<a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3329f765",
   "metadata": {},
   "source": [
    "Применим метод TF-IDF:  Проведём лемматизацию слов с помощью WordNetLemmatizer() из библиотеки nltk. Почистим данные от числовых значений, никнеймов и хэштегов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6b5ad",
   "metadata": {},
   "source": [
    "Почистим данные от числовых значений, никнеймов и хэштегов. Слова с апострофами нормализуем. Для нормализации используем готовый словарь сокращений английских слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67c07f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \"ain't\": \"are not\", \"'s\":\" is\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"‘cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"they'd\": \"they would\", \"they'd've\": \"they would have\",\"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what've\": \"what have\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who've\": \"who have\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a6c1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_re = re.compile('(%s)'%'|'.join(contractions_dict.keys()))\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    text = text.lower()\n",
    "    text = contractions_re.sub(replace, text)\n",
    "    clean_text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|([^'A-Za-z])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, 'v') for w in nltk.word_tokenize(clean_text)]).replace(\"'\", \"\").strip()\n",
    "\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85a692ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmas'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "959f0b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he match this background colour i m seemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it be j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can not make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              lemmas  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  daww he match this background colour i m seemi...  \n",
       "2  hey man i m really not try to edit war it be j...  \n",
       "3  more i can not make any real suggestions on im...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a3f43",
   "metadata": {},
   "source": [
    "Так же, как и в предыдущем блоке, рассмотрим 3 модели: логистическая регрессия, LightGBM, случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "569d655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = data.drop(['toxic'], axis = 1)\n",
    "target_2 = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd7d481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2_train, features_2_valid, target_2_train, target_2_valid = train_test_split(features_2, target_2, test_size = 0.2, random_state = 12345, stratify = target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75531ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2_valid, features_2_test, target_2_valid, target_2_test  = train_test_split(features_2_valid, target_2_valid, test_size = 0.5, random_state = 12345, stratify = target_2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ba3220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce79317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1f9878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2_train = count_tf_idf.fit_transform(features_2_train['lemmas'].values.astype('U'))\n",
    "features_2_valid = count_tf_idf.transform(features_2_valid['lemmas'].values.astype('U'))\n",
    "features_2_test = count_tf_idf.transform(features_2_test['lemmas'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bbfeb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656, 132877)\n",
      "(15957, 132877)\n",
      "(15958, 132877)\n"
     ]
    }
   ],
   "source": [
    "print(features_2_train.shape)\n",
    "print(features_2_valid.shape)\n",
    "print(features_2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e595e5",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35810d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_2 = LogisticRegression(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ca442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log_2 = {\n",
    "    'solver': ['liblinear', 'sag','saga','newton-cg'],\n",
    "    'C': [0.5,1.0,1.5],\n",
    "    'intercept_scaling':[0.5,1.0,1.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c05461f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                random_state=12345),\n",
       "                   param_distributions={'C': [0.5, 1.0, 1.5],\n",
       "                                        'intercept_scaling': [0.5, 1.0, 1.5],\n",
       "                                        'solver': ['liblinear', 'sag', 'saga',\n",
       "                                                   'newton-cg']},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_2_grid = RandomizedSearchCV(model_log_2, params_log_2, scoring='f1')\n",
    "model_log_2_grid.fit(features_2_train, target_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e471b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия. Гиперпараметры  {'solver': 'sag', 'intercept_scaling': 0.5, 'C': 1.5}\n",
      "Логистическая регрессия. F1  0.7538282119093229\n"
     ]
    }
   ],
   "source": [
    "print('Логистическая регрессия. Гиперпараметры ', model_log_2_grid.best_params_)\n",
    "print('Логистическая регрессия. F1 ', model_log_2_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f46ef",
   "metadata": {},
   "source": [
    "#### LightGBM <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5a55e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_2 = LGBMClassifier(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a6af214",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_2 = {\n",
    "    'objective': ['regression','binary'],\n",
    "    'boosting_type' : ['dart','gbdt','goss'],\n",
    "    'max_depth': [15,30],\n",
    "    'num_leaves': [10,200,250]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae0498f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                            random_state=12345),\n",
       "                   param_distributions={'boosting_type': ['dart', 'gbdt',\n",
       "                                                          'goss'],\n",
       "                                        'max_depth': [15, 30],\n",
       "                                        'num_leaves': [10, 200, 250],\n",
       "                                        'objective': ['regression', 'binary']},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb_2_grid = RandomizedSearchCV(model_lgb_2, lgb_params_2, scoring='f1')\n",
    "model_lgb_2_grid.fit(features_2_train, target_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc2a1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM. Гиперпараметры  {'objective': 'binary', 'num_leaves': 200, 'max_depth': 30, 'boosting_type': 'goss'}\n",
      "LightGBM. F1  0.7463515795992002\n"
     ]
    }
   ],
   "source": [
    "print('LightGBM. Гиперпараметры ', model_lgb_2_grid.best_params_)\n",
    "print('LightGBM. F1 ', model_lgb_2_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59e08e",
   "metadata": {},
   "source": [
    "#### Случайный лес <a class=\"anchor\" id=\"section_3_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "119f0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest_2 = RandomForestClassifier(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff5ad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params_2 = {\n",
    "    'max_depth': range(1, 26),\n",
    "    'n_estimators':range(1, 11)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e150149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                    random_state=12345),\n",
       "                   param_distributions={'max_depth': range(1, 26),\n",
       "                                        'n_estimators': range(1, 11)},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest_2_grid = RandomizedSearchCV(model_forest_2, forest_params_2, scoring='f1')\n",
    "model_forest_2_grid.fit(features_2_train, target_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04602dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес. Гиперпараметры  {'n_estimators': 9, 'max_depth': 17}\n",
      "Случайный лес. F1  0.331443633785591\n"
     ]
    }
   ],
   "source": [
    "print('Случайный лес. Гиперпараметры ', model_forest_2_grid.best_params_)\n",
    "print('Случайный лес. F1 ', model_forest_2_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3325b3",
   "metadata": {},
   "source": [
    "#### Вывод <a class=\"anchor\" id=\"section_3_4\"></a>\n",
    "Из рассмотренных моделей: логистическая регрессия, LightGBM, случайный лес, только логистическая регрессия (гиперпараметры:  'solver': 'sag', 'intercept_scaling': 0.5, 'C': 1.5) позволила получить требуемое значение метрики качества F1 не меньше 0.75 - 0.753. Именно эту модель мы и протестируем."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51753c",
   "metadata": {},
   "source": [
    "### Тестирование лучшей модели<a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "327011cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия. Тест. F1 0.74\n"
     ]
    }
   ],
   "source": [
    "model_best = LogisticRegression(**model_log_2_grid.best_params_)\n",
    "model_best.fit(features_2_train, target_2_train)\n",
    "predictions_test = model_best.predict(features_2_test)\n",
    "f1_Score = f1_score(target_2_test, predictions_test)\n",
    "print('Логистическая регрессия. Тест. F1', f1_Score.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970f373",
   "metadata": {},
   "source": [
    "Из рассмотренных моделей лучшее значение метрики качества F1 на обучающей выборке у логистической регресии (гиперпараметры:  'solver': 'sag', 'intercept_scaling': 0.5, 'C': 1.5). На тестовой чуть ниже - 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d475d26",
   "metadata": {},
   "source": [
    "### Итоговый вывод<a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f97ef",
   "metadata": {},
   "source": [
    "В полученной базе данных содержится 159571 записей. Текст комментариев - английский. Отрицательные комментарии составляют 10.2%.\n",
    "В ходе работ были проанализированы 2 подхода - применение предобученной модели DistilBert для  токенизации текстов и создания эмбеддингов. Второй подход - применение метода TF-IDF.\n",
    "В обоих случаях для обучения применялись модели: логистическая регрессия, LightGBM, случайный лес.\n",
    "Лучший результат метрики качества F1 на обучающей выборке (0.753) получен при применении метода TF-IDF и логистической регрессии (гиперпараметры:  'solver': 'sag', 'intercept_scaling': 0.5, 'C': 1.5). На тестовой результат чуть хуже - F1 = 0.74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cb1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
